name: "[internal] Produce data for external analysis"

on:
  workflow_call:
  workflow_dispatch:
    inputs:
      test_workflow_run_id:
        description: "Unique GitHub workflow run ID to use for data"
        default: 9605916313
        type: number
  workflow_run:
    workflows:
      - "All post-commit tests"
      - "(T3K) T3000 demo tests"
      - "(T3K) T3000 model perf tests"
      - "(Single-card) Model perf tests"
      - "(Single-card) Device perf tests"
    types:
      - completed

jobs:
  produce-cicd-data:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Output (safe) pipeline values
        run: |
          echo "pipeline_id (id / run #): ${{ github.run_id }}/${{ github.run_attempt }}"
          echo "submissions_ts: "
          echo "start_ts: "
          echo "end_ts: "
          echo "name: ${{ github.workflow }}, but rk recommended name w/out @: ${{ github.workflow_ref }}"
          echo "trigger: ${{ github.event_name }}"
          echo "sha: ${{ github.sha }}"
          echo "(triggering) author/actor: ${{ github.actor }}"
          echo "author/actor: ${{ github.triggering_actor }}"
          echo "orchestrator: github (Static)"
          echo "docker_image: ${{ job.container.image }}"
          echo "build duration is post-process"
      - name: Output auxiliary values (workflow dispatch)
        if: ${{ github.event_name == 'workflow_dispatch' }}
        env:
          GH_TOKEN: ${{ github.token }}
        run: |
          echo "[Info] Workflow run attempt"
          gh api /repos/tenstorrent/tt-metal/actions/runs/${{ inputs.test_workflow_run_id }}/attempts/1
          gh api /repos/tenstorrent/tt-metal/actions/runs/${{ inputs.test_workflow_run_id }}/attempts/1 > workflow.json
          echo "[Info] Workflow run attempt jobs"
          gh api --paginate /repos/tenstorrent/tt-metal/actions/runs/${{ inputs.test_workflow_run_id }}/attempts/1/jobs
          gh api --paginate /repos/tenstorrent/tt-metal/actions/runs/${{ inputs.test_workflow_run_id }}/attempts/1/jobs > workflow_jobs.json
      - name: Output auxiliary values (workflow_run completed)
        if: ${{ github.event_name == 'workflow_run' }}
        env:
          GH_TOKEN: ${{ github.token }}
        run: |
          echo "[Info] Workflow run attempt"
          gh api /repos/tenstorrent/tt-metal/actions/runs/${{ github.event.workflow_run.id }}/attempts/${{ github.event.workflow_run.run_attempt }} > workflow.json
          echo "[Info] Workflow run attempt jobs"
          gh api --paginate /repos/tenstorrent/tt-metal/actions/runs/${{ github.event.workflow_run.id }}/attempts/${{ github.event.workflow_run.run_attempt }}/jobs > workflow_jobs.json
      - uses: actions/setup-python@v5
        with:
          python-version: '3.8'
          cache: 'pip'
      - name: Install infra dependencies
        run: pip3 install -r infra/requirements-infra.txt
      - name: Create CSVs and show
        env:
          PYTHONPATH: ${{ github.workspace }}
        run: python3 .github/scripts/data_analysis/create_pipeline_csvs.py
      - name: Show directory to see output files
        run: ls -hal
      - name: Show CSVs output
        run: cat *.csv
      - name: Upload workflow run data, even on failure
        if: ${{ !cancelled() }}
        uses: actions/upload-artifact@v4
        with:
          name: workflow-run-data
          path: |
            if-no-files-found: warn
            path: |
              workflow.json
              workflow_jobs.json
  test-produce-benchmark-environment:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: create dummy
        shell: bash
        run: |
          mkdir -p generated/benchmark_data
          touch 'generated/benchmark_data/measurement_2024-07-12T05:01:45+0000.csv'
          touch 'generated/benchmark_data/measurement_2024-07-12T04:59:14+0000.csv'
          touch 'generated/benchmark_data/measurement_2024-07-12T05:03:29+0000.csv'
      - name: sdf
        env:
          PYTHONPATH: ${{ github.workspace }}
          ARCH_NAME: grayskull
        run: pip3 install loguru && python3 .github/scripts/data_analysis/create_benchmark_environment_csv.py
      - name: Show files
        shell: bash
        run: find generated/benchmark_data -type f | xargs -n 1 -I {} bash -c 'echo {} && cat {}'
